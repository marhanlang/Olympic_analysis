{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Olympic_NN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbCW_vWejV5o",
        "outputId": "2ed025d0-8e6b-405d-e5a9-7718219761b2"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import sklearn as skl\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "spark_version = 'spark-3.1.2'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql.functions import col"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 14.2 kB/88.7\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 88.7 kB in 3s (32.5 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_DuJfo3jdh3",
        "outputId": "d0ec76ae-6925-40da-bfda-5734edf8749a"
      },
      "source": [
        "# download a Postgres driver\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.16.jar"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-04 16:13:51--  https://jdbc.postgresql.org/download/postgresql-42.2.16.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1002883 (979K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.16.jar.4’\n",
            "\n",
            "postgresql-42.2.16. 100%[===================>] 979.38K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-08-04 16:13:52 (6.50 MB/s) - ‘postgresql-42.2.16.jar.4’ saved [1002883/1002883]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tth766yk3pv"
      },
      "source": [
        "# start a Spark session with driver\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Olympic-Analysis\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.16.jar\").getOrCreate()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmS3kRX-lBXP"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url =\"https://olympicclassproject.s3.us-east-2.amazonaws.com/cleandatabmi.xlsb.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "cleandatadf = spark.read.csv(SparkFiles.get(\"cleandatabmi.xlsb.csv\"), sep=\",\", header=True, inferSchema=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npTJSrErlVS-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9096d364-68ef-4e70-8aa9-f397b189a894"
      },
      "source": [
        "# Show DataFrame\n",
        "cleandatadf.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+---+---+------+------+-----------+-----------+------+--------------------+------+---+\n",
            "|                Name|Sex|Age|Height|Weight|       Team|      Games|Season|               Event| Medal|BMI|\n",
            "+--------------------+---+---+------+------+-----------+-----------+------+--------------------+------+---+\n",
            "|Juhamatti Tapio A...|  M| 28|   184|    85|    Finland|2014 Winter|Winter|Ice Hockey Men's ...|Bronze| 25|\n",
            "|Paavo Johannes Aa...|  M| 28|   175|    64|    Finland|1948 Summer|Summer|Gymnastics Men's ...|Bronze| 21|\n",
            "|Paavo Johannes Aa...|  M| 28|   175|    64|    Finland|1948 Summer|Summer|Gymnastics Men's ...|  Gold| 21|\n",
            "|Paavo Johannes Aa...|  M| 28|   175|    64|    Finland|1948 Summer|Summer|Gymnastics Men's ...|  Gold| 21|\n",
            "|Paavo Johannes Aa...|  M| 28|   175|    64|    Finland|1948 Summer|Summer|Gymnastics Men's ...|  Gold| 21|\n",
            "|Paavo Johannes Aa...|  M| 32|   175|    64|    Finland|1952 Summer|Summer|Gymnastics Men's ...|Bronze| 21|\n",
            "|  Kjetil Andr Aamodt|  M| 20|   176|    85|     Norway|1992 Winter|Winter|Alpine Skiing Men...|  Gold| 27|\n",
            "|  Kjetil Andr Aamodt|  M| 20|   176|    85|     Norway|1992 Winter|Winter|Alpine Skiing Men...|Bronze| 27|\n",
            "|  Kjetil Andr Aamodt|  M| 22|   176|    85|     Norway|1994 Winter|Winter|Alpine Skiing Men...|Silver| 27|\n",
            "|  Kjetil Andr Aamodt|  M| 22|   176|    85|     Norway|1994 Winter|Winter|Alpine Skiing Men...|Bronze| 27|\n",
            "|  Kjetil Andr Aamodt|  M| 22|   176|    85|     Norway|1994 Winter|Winter|Alpine Skiing Men...|Silver| 27|\n",
            "|  Kjetil Andr Aamodt|  M| 30|   176|    85|     Norway|2002 Winter|Winter|Alpine Skiing Men...|  Gold| 27|\n",
            "|  Kjetil Andr Aamodt|  M| 30|   176|    85|     Norway|2002 Winter|Winter|Alpine Skiing Men...|  Gold| 27|\n",
            "|  Kjetil Andr Aamodt|  M| 34|   176|    85|     Norway|2006 Winter|Winter|Alpine Skiing Men...|  Gold| 27|\n",
            "|    Pepijn Aardewijn|  M| 26|   189|    72|Netherlands|1996 Summer|Summer|Rowing Men's Ligh...|Silver| 20|\n",
            "|  Ann Kristin Aarnes|  F| 23|   182|    64|     Norway|1996 Summer|Summer|Football Women's ...|Bronze| 19|\n",
            "|   Giovanni Abagnale|  M| 21|   198|    90|      Italy|2016 Summer|Summer|Rowing Men's Coxl...|Bronze| 23|\n",
            "| Jos Luis Abajo Gmez|  M| 30|   194|    87|      Spain|2008 Summer|Summer|Fencing Men's epe...|Bronze| 23|\n",
            "|   Patimat Abakarova|  F| 21|   165|    49| Azerbaijan|2016 Summer|Summer|Taekwondo Women's...|Bronze| 18|\n",
            "|Mariya Vasilyevna...|  F| 22|   179|    80|     Russia|2008 Summer|Summer|Athletics Women's...|Silver| 25|\n",
            "+--------------------+---+---+------+------+-----------+-----------+------+--------------------+------+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPaSLrwtFF6p",
        "outputId": "7f1d2294-bbd8-4a38-f0d1-b6e676a35fbf"
      },
      "source": [
        "#Assign Medal types a number\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "indexer = StringIndexer(inputCol=\"Medal\", outputCol=\"Medals\") \n",
        "cleandatadf = indexer.fit(cleandatadf).transform(cleandatadf) \n",
        "cleandatadf = cleandatadf.drop('Medal')\n",
        "cleandatadf.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+---+---+------+------+-----------+-----------+------+--------------------+---+------+\n",
            "|                Name|Sex|Age|Height|Weight|       Team|      Games|Season|               Event|BMI|Medals|\n",
            "+--------------------+---+---+------+------+-----------+-----------+------+--------------------+---+------+\n",
            "|Juhamatti Tapio A...|  M| 28|   184|    85|    Finland|2014 Winter|Winter|Ice Hockey Men's ...| 25|   0.0|\n",
            "|Paavo Johannes Aa...|  M| 28|   175|    64|    Finland|1948 Summer|Summer|Gymnastics Men's ...| 21|   0.0|\n",
            "|Paavo Johannes Aa...|  M| 28|   175|    64|    Finland|1948 Summer|Summer|Gymnastics Men's ...| 21|   1.0|\n",
            "|Paavo Johannes Aa...|  M| 28|   175|    64|    Finland|1948 Summer|Summer|Gymnastics Men's ...| 21|   1.0|\n",
            "|Paavo Johannes Aa...|  M| 28|   175|    64|    Finland|1948 Summer|Summer|Gymnastics Men's ...| 21|   1.0|\n",
            "|Paavo Johannes Aa...|  M| 32|   175|    64|    Finland|1952 Summer|Summer|Gymnastics Men's ...| 21|   0.0|\n",
            "|  Kjetil Andr Aamodt|  M| 20|   176|    85|     Norway|1992 Winter|Winter|Alpine Skiing Men...| 27|   1.0|\n",
            "|  Kjetil Andr Aamodt|  M| 20|   176|    85|     Norway|1992 Winter|Winter|Alpine Skiing Men...| 27|   0.0|\n",
            "|  Kjetil Andr Aamodt|  M| 22|   176|    85|     Norway|1994 Winter|Winter|Alpine Skiing Men...| 27|   2.0|\n",
            "|  Kjetil Andr Aamodt|  M| 22|   176|    85|     Norway|1994 Winter|Winter|Alpine Skiing Men...| 27|   0.0|\n",
            "|  Kjetil Andr Aamodt|  M| 22|   176|    85|     Norway|1994 Winter|Winter|Alpine Skiing Men...| 27|   2.0|\n",
            "|  Kjetil Andr Aamodt|  M| 30|   176|    85|     Norway|2002 Winter|Winter|Alpine Skiing Men...| 27|   1.0|\n",
            "|  Kjetil Andr Aamodt|  M| 30|   176|    85|     Norway|2002 Winter|Winter|Alpine Skiing Men...| 27|   1.0|\n",
            "|  Kjetil Andr Aamodt|  M| 34|   176|    85|     Norway|2006 Winter|Winter|Alpine Skiing Men...| 27|   1.0|\n",
            "|    Pepijn Aardewijn|  M| 26|   189|    72|Netherlands|1996 Summer|Summer|Rowing Men's Ligh...| 20|   2.0|\n",
            "|  Ann Kristin Aarnes|  F| 23|   182|    64|     Norway|1996 Summer|Summer|Football Women's ...| 19|   0.0|\n",
            "|   Giovanni Abagnale|  M| 21|   198|    90|      Italy|2016 Summer|Summer|Rowing Men's Coxl...| 23|   0.0|\n",
            "| Jos Luis Abajo Gmez|  M| 30|   194|    87|      Spain|2008 Summer|Summer|Fencing Men's epe...| 23|   0.0|\n",
            "|   Patimat Abakarova|  F| 21|   165|    49| Azerbaijan|2016 Summer|Summer|Taekwondo Women's...| 18|   0.0|\n",
            "|Mariya Vasilyevna...|  F| 22|   179|    80|     Russia|2008 Summer|Summer|Athletics Women's...| 25|   2.0|\n",
            "+--------------------+---+---+------+------+-----------+-----------+------+--------------------+---+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22qW-LENruDo"
      },
      "source": [
        "pandas_df=cleandatadf.toPandas()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "s4cKn6126PZm",
        "outputId": "cbd6e6e5-2f98-4ccb-bdf9-d6b955721b5b"
      },
      "source": [
        "#Drop non-feature columns\n",
        "pandas_df.drop(['Name', \"Sex\", \"Team\", \"Games\", \"Season\", \"Event\"], inplace=True, axis=1)\n",
        "pandas_df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Medals</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28</td>\n",
              "      <td>184</td>\n",
              "      <td>85</td>\n",
              "      <td>25</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28</td>\n",
              "      <td>175</td>\n",
              "      <td>64</td>\n",
              "      <td>21</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>175</td>\n",
              "      <td>64</td>\n",
              "      <td>21</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>28</td>\n",
              "      <td>175</td>\n",
              "      <td>64</td>\n",
              "      <td>21</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>175</td>\n",
              "      <td>64</td>\n",
              "      <td>21</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Age  Height  Weight BMI  Medals\n",
              "0  28     184      85  25     0.0\n",
              "1  28     175      64  21     0.0\n",
              "2  28     175      64  21     1.0\n",
              "3  28     175      64  21     1.0\n",
              "4  28     175      64  21     1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URddZmCu5r5Y",
        "outputId": "6093ae26-fd1e-4e1b-be60-342b240ccee2"
      },
      "source": [
        "pandas_df.nunique(axis=0)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age        52\n",
              "Height    111\n",
              "Weight    160\n",
              "BMI        40\n",
              "Medals     80\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_6yCX1E7TKA",
        "outputId": "44efd3d6-cc71-4ab7-bf87-7dd8e0bc181b"
      },
      "source": [
        "#create categorical variable list for encoding\n",
        "olympic_cat = pandas_df.dtypes[pandas_df.dtypes == \"object\"].index.tolist()\n",
        "olympic_cat"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Age', 'BMI']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRXadJIX7e5m"
      },
      "source": [
        "# Create a OneHotEncoder instance\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Fit and transform the OneHotEncoder using the categorical variable list\n",
        "encode_df = pd.DataFrame(enc.fit_transform(pandas_df[olympic_cat]))\n",
        "\n",
        "# Add the encoded variable names to the dataframe\n",
        "encode_df.columns = enc.get_feature_names(olympic_cat)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "UGJ-Uxa67nOo",
        "outputId": "588620b0-a218-4028-9185-4ba538e66d00"
      },
      "source": [
        "#Merge encoded values and numbered medals and drop original columns\n",
        "pandas_df = pandas_df.merge(encode_df,left_index=True, right_index=True)\n",
        "pandas_df = pandas_df.drop(olympic_cat,1)\n",
        "\n",
        "pandas_df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Medals</th>\n",
              "      <th>Age_13</th>\n",
              "      <th>Age_14</th>\n",
              "      <th>Age_15</th>\n",
              "      <th>Age_16</th>\n",
              "      <th>Age_17</th>\n",
              "      <th>Age_18</th>\n",
              "      <th>Age_19</th>\n",
              "      <th>Age_20</th>\n",
              "      <th>Age_21</th>\n",
              "      <th>Age_22</th>\n",
              "      <th>Age_23</th>\n",
              "      <th>Age_24</th>\n",
              "      <th>Age_25</th>\n",
              "      <th>Age_26</th>\n",
              "      <th>Age_27</th>\n",
              "      <th>Age_28</th>\n",
              "      <th>Age_29</th>\n",
              "      <th>Age_30</th>\n",
              "      <th>Age_31</th>\n",
              "      <th>Age_32</th>\n",
              "      <th>Age_33</th>\n",
              "      <th>Age_34</th>\n",
              "      <th>Age_35</th>\n",
              "      <th>Age_36</th>\n",
              "      <th>Age_37</th>\n",
              "      <th>Age_38</th>\n",
              "      <th>Age_39</th>\n",
              "      <th>Age_40</th>\n",
              "      <th>Age_41</th>\n",
              "      <th>Age_42</th>\n",
              "      <th>Age_43</th>\n",
              "      <th>Age_44</th>\n",
              "      <th>Age_45</th>\n",
              "      <th>Age_46</th>\n",
              "      <th>Age_47</th>\n",
              "      <th>Age_48</th>\n",
              "      <th>Age_49</th>\n",
              "      <th>...</th>\n",
              "      <th>BMI_13</th>\n",
              "      <th>BMI_14</th>\n",
              "      <th>BMI_15</th>\n",
              "      <th>BMI_16</th>\n",
              "      <th>BMI_17</th>\n",
              "      <th>BMI_18</th>\n",
              "      <th>BMI_19</th>\n",
              "      <th>BMI_20</th>\n",
              "      <th>BMI_21</th>\n",
              "      <th>BMI_22</th>\n",
              "      <th>BMI_23</th>\n",
              "      <th>BMI_24</th>\n",
              "      <th>BMI_25</th>\n",
              "      <th>BMI_26</th>\n",
              "      <th>BMI_27</th>\n",
              "      <th>BMI_28</th>\n",
              "      <th>BMI_29</th>\n",
              "      <th>BMI_30</th>\n",
              "      <th>BMI_31</th>\n",
              "      <th>BMI_32</th>\n",
              "      <th>BMI_33</th>\n",
              "      <th>BMI_34</th>\n",
              "      <th>BMI_35</th>\n",
              "      <th>BMI_36</th>\n",
              "      <th>BMI_37</th>\n",
              "      <th>BMI_38</th>\n",
              "      <th>BMI_39</th>\n",
              "      <th>BMI_40</th>\n",
              "      <th>BMI_41</th>\n",
              "      <th>BMI_42</th>\n",
              "      <th>BMI_43</th>\n",
              "      <th>BMI_44</th>\n",
              "      <th>BMI_45</th>\n",
              "      <th>BMI_46</th>\n",
              "      <th>BMI_47</th>\n",
              "      <th>BMI_51</th>\n",
              "      <th>BMI_56</th>\n",
              "      <th>BMI_Bronze</th>\n",
              "      <th>BMI_Gold</th>\n",
              "      <th>BMI_Silver</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>184</td>\n",
              "      <td>85</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>175</td>\n",
              "      <td>64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>175</td>\n",
              "      <td>64</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>175</td>\n",
              "      <td>64</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>175</td>\n",
              "      <td>64</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 95 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Height  Weight  Medals  Age_13  ...  BMI_56  BMI_Bronze  BMI_Gold  BMI_Silver\n",
              "0     184      85     0.0     0.0  ...     0.0         0.0       0.0         0.0\n",
              "1     175      64     0.0     0.0  ...     0.0         0.0       0.0         0.0\n",
              "2     175      64     1.0     0.0  ...     0.0         0.0       0.0         0.0\n",
              "3     175      64     1.0     0.0  ...     0.0         0.0       0.0         0.0\n",
              "4     175      64     1.0     0.0  ...     0.0         0.0       0.0         0.0\n",
              "\n",
              "[5 rows x 95 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhFd4xVHJpWF"
      },
      "source": [
        "# Split preprocessed data into features and target arrays\n",
        "y = pandas_df[\"Medals\"].values\n",
        "X = pandas_df.drop([\"Medals\"],1).values\n",
        "\n",
        "# Split the preprocessed data into training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X88Jkmk1sYeO"
      },
      "source": [
        "# Create StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0bznTDjOFbA",
        "outputId": "8e49d510-093b-4c92-999b-4dff7e7ba9c0"
      },
      "source": [
        "# Define model\n",
        "number_input_features = len(X_train[0])\n",
        "hidden_nodes_layer1 =  60\n",
        "hidden_nodes_layer2 = 4\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
        "\n",
        "nn.add(tf.keras.layers.Dense(units=4, activation=\"tanh\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 60)                5700      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 244       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 5,969\n",
            "Trainable params: 5,969\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWE0ymNaKZU6"
      },
      "source": [
        "# Compile model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9AsSXYW4UuJ",
        "outputId": "57a806e1-53d0-4fe3-f5ca-a930ee79b4de"
      },
      "source": [
        "# Train model\n",
        "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "708/708 [==============================] - 2s 2ms/step - loss: -0.0774 - accuracy: 0.3341\n",
            "Epoch 2/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -0.4503 - accuracy: 0.3340\n",
            "Epoch 3/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -0.6327 - accuracy: 0.3339\n",
            "Epoch 4/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -0.7977 - accuracy: 0.3341\n",
            "Epoch 5/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -0.9594 - accuracy: 0.3336\n",
            "Epoch 6/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -1.1194 - accuracy: 0.3340\n",
            "Epoch 7/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -1.2810 - accuracy: 0.3340\n",
            "Epoch 8/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -1.4621 - accuracy: 0.3345\n",
            "Epoch 9/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -1.6377 - accuracy: 0.3342\n",
            "Epoch 10/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -1.8249 - accuracy: 0.3341\n",
            "Epoch 11/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -2.0131 - accuracy: 0.3343\n",
            "Epoch 12/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -2.1976 - accuracy: 0.3343\n",
            "Epoch 13/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -2.3837 - accuracy: 0.3346\n",
            "Epoch 14/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -2.5689 - accuracy: 0.3342\n",
            "Epoch 15/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -2.7695 - accuracy: 0.3345\n",
            "Epoch 16/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -2.9610 - accuracy: 0.3345\n",
            "Epoch 17/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -3.1591 - accuracy: 0.3347\n",
            "Epoch 18/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -3.3570 - accuracy: 0.3346\n",
            "Epoch 19/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -3.5455 - accuracy: 0.3347\n",
            "Epoch 20/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -3.7301 - accuracy: 0.3351\n",
            "Epoch 21/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -3.9238 - accuracy: 0.3349\n",
            "Epoch 22/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -4.1113 - accuracy: 0.3351\n",
            "Epoch 23/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -4.3022 - accuracy: 0.3343\n",
            "Epoch 24/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -4.5161 - accuracy: 0.3351\n",
            "Epoch 25/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -4.7186 - accuracy: 0.3347\n",
            "Epoch 26/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -4.9123 - accuracy: 0.3351\n",
            "Epoch 27/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -5.0922 - accuracy: 0.3348\n",
            "Epoch 28/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -5.2812 - accuracy: 0.3350\n",
            "Epoch 29/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -5.5028 - accuracy: 0.3352\n",
            "Epoch 30/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -5.6992 - accuracy: 0.3352\n",
            "Epoch 31/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -5.9046 - accuracy: 0.3350\n",
            "Epoch 32/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -6.0800 - accuracy: 0.3354\n",
            "Epoch 33/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -6.3011 - accuracy: 0.3356\n",
            "Epoch 34/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -6.5116 - accuracy: 0.3352\n",
            "Epoch 35/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -6.7055 - accuracy: 0.3362\n",
            "Epoch 36/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -6.9384 - accuracy: 0.3351\n",
            "Epoch 37/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -7.0988 - accuracy: 0.3354\n",
            "Epoch 38/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -7.3240 - accuracy: 0.3358\n",
            "Epoch 39/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -7.5329 - accuracy: 0.3350\n",
            "Epoch 40/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -7.7786 - accuracy: 0.3350\n",
            "Epoch 41/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -7.9878 - accuracy: 0.3352\n",
            "Epoch 42/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -8.1685 - accuracy: 0.3355\n",
            "Epoch 43/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -8.3891 - accuracy: 0.3355\n",
            "Epoch 44/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -8.6479 - accuracy: 0.3351\n",
            "Epoch 45/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -8.8547 - accuracy: 0.3357\n",
            "Epoch 46/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -9.0672 - accuracy: 0.3357\n",
            "Epoch 47/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -9.3172 - accuracy: 0.3357\n",
            "Epoch 48/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -9.5503 - accuracy: 0.3358\n",
            "Epoch 49/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -9.7520 - accuracy: 0.3358\n",
            "Epoch 50/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -9.9567 - accuracy: 0.3354\n",
            "Epoch 51/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -10.1440 - accuracy: 0.3351\n",
            "Epoch 52/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -10.3852 - accuracy: 0.3350\n",
            "Epoch 53/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -10.6211 - accuracy: 0.3354\n",
            "Epoch 54/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -10.8620 - accuracy: 0.3353\n",
            "Epoch 55/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -10.9565 - accuracy: 0.3354\n",
            "Epoch 56/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -11.1913 - accuracy: 0.3356\n",
            "Epoch 57/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -11.4118 - accuracy: 0.3364\n",
            "Epoch 58/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -11.6299 - accuracy: 0.3359\n",
            "Epoch 59/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -11.8697 - accuracy: 0.3359\n",
            "Epoch 60/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -11.9857 - accuracy: 0.3359\n",
            "Epoch 61/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -12.2071 - accuracy: 0.3352\n",
            "Epoch 62/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -12.4156 - accuracy: 0.3348\n",
            "Epoch 63/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -12.6956 - accuracy: 0.3351\n",
            "Epoch 64/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -12.8546 - accuracy: 0.3352\n",
            "Epoch 65/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -13.0709 - accuracy: 0.3354\n",
            "Epoch 66/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -13.4055 - accuracy: 0.3351\n",
            "Epoch 67/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -13.5428 - accuracy: 0.3359\n",
            "Epoch 68/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -13.7609 - accuracy: 0.3363\n",
            "Epoch 69/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -13.9832 - accuracy: 0.3359\n",
            "Epoch 70/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -14.1977 - accuracy: 0.3355\n",
            "Epoch 71/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -14.3537 - accuracy: 0.3350\n",
            "Epoch 72/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -14.6596 - accuracy: 0.3351\n",
            "Epoch 73/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -14.8338 - accuracy: 0.3346\n",
            "Epoch 74/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -15.0561 - accuracy: 0.3357\n",
            "Epoch 75/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -15.2805 - accuracy: 0.3355\n",
            "Epoch 76/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -15.5609 - accuracy: 0.3353\n",
            "Epoch 77/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -15.7658 - accuracy: 0.3346\n",
            "Epoch 78/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -16.0082 - accuracy: 0.3355\n",
            "Epoch 79/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -16.2031 - accuracy: 0.3346\n",
            "Epoch 80/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -16.4973 - accuracy: 0.3355\n",
            "Epoch 81/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -16.6888 - accuracy: 0.3355\n",
            "Epoch 82/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -16.9502 - accuracy: 0.3354\n",
            "Epoch 83/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -17.1994 - accuracy: 0.3351\n",
            "Epoch 84/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -17.4232 - accuracy: 0.3349\n",
            "Epoch 85/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -17.6920 - accuracy: 0.3358\n",
            "Epoch 86/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -17.9232 - accuracy: 0.3350\n",
            "Epoch 87/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -18.1236 - accuracy: 0.3348\n",
            "Epoch 88/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -18.3144 - accuracy: 0.3349\n",
            "Epoch 89/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -18.5426 - accuracy: 0.3349\n",
            "Epoch 90/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -18.7252 - accuracy: 0.3349\n",
            "Epoch 91/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -19.1093 - accuracy: 0.3352\n",
            "Epoch 92/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -19.2834 - accuracy: 0.3352\n",
            "Epoch 93/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -19.5641 - accuracy: 0.3351\n",
            "Epoch 94/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -19.7503 - accuracy: 0.3347\n",
            "Epoch 95/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -19.9752 - accuracy: 0.3348\n",
            "Epoch 96/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -20.2134 - accuracy: 0.3351\n",
            "Epoch 97/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -20.3261 - accuracy: 0.3351\n",
            "Epoch 98/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -20.6295 - accuracy: 0.3347\n",
            "Epoch 99/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -20.9281 - accuracy: 0.3343\n",
            "Epoch 100/100\n",
            "708/708 [==============================] - 1s 2ms/step - loss: -21.1463 - accuracy: 0.3345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNB9K_qh4W-E",
        "outputId": "958ac7df-5ef2-4ea0-9e5b-a3016a935205"
      },
      "source": [
        "# Evaluate model using test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "236/236 - 0s - loss: -1.0933e+01 - accuracy: 0.3343\n",
            "Loss: -10.933160781860352, Accuracy: 0.3343493342399597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmi32FdR4ZPu"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}